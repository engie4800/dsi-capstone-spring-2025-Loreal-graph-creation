{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai (from -r requirements.txt (line 1))\n",
      "  Downloading openai-1.63.2-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting graphdatascience (from -r requirements.txt (line 2))\n",
      "  Downloading graphdatascience-1.13-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting retry==0.9.2 (from -r requirements.txt (line 3))\n",
      "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain>=0.0.216 (from -r requirements.txt (line 4))\n",
      "  Downloading langchain-0.3.19-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting streamlit==1.23.1 (from -r requirements.txt (line 5))\n",
      "  Downloading streamlit-1.23.1-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting streamlit-chat==0.0.2.2 (from -r requirements.txt (line 6))\n",
      "  Downloading streamlit_chat-0.0.2.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting streamlit-chat-media==0.0.4 (from -r requirements.txt (line 7))\n",
      "  Downloading streamlit_chat_media-0.0.4-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: numpy in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.2.3)\n",
      "Requirement already satisfied: pandas in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (2.2.3)\n",
      "Collecting plotly==5.15.0 (from -r requirements.txt (line 10))\n",
      "  Downloading plotly-5.15.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting altair<5 (from -r requirements.txt (line 11))\n",
      "  Downloading altair-4.2.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting python-dotenv==1.0.0 (from -r requirements.txt (line 12))\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from retry==0.9.2->-r requirements.txt (line 3)) (5.1.1)\n",
      "Collecting py<2.0.0,>=1.4.26 (from retry==0.9.2->-r requirements.txt (line 3))\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading cachetools-5.5.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting importlib-metadata<7,>=1.4 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting numpy (from -r requirements.txt (line 8))\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting packaging<24,>=14.1 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow<10,>=6.2.0 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading Pillow-9.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting protobuf<5,>=3.20 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from streamlit==1.23.1->-r requirements.txt (line 5)) (19.0.0)\n",
      "Collecting pympler<2,>=0.9 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading Pympler-1.1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from streamlit==1.23.1->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3,>=2.4 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from streamlit==1.23.1->-r requirements.txt (line 5)) (2.32.3)\n",
      "Collecting rich<14,>=10.11.0 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tenacity<9,>=8.0.0 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from streamlit==1.23.1->-r requirements.txt (line 5)) (4.12.2)\n",
      "Collecting tzlocal<5,>=1.1 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading tzlocal-4.3.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.1.dev5 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from streamlit==1.23.1->-r requirements.txt (line 5)) (6.4.2)\n",
      "Collecting anyio<5,>=3.5.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading anyio-4.8.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading jiter-0.8.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r requirements.txt (line 1))\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting sniffio (from openai->-r requirements.txt (line 1))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>4 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (4.67.1)\n",
      "Collecting multimethod<2.0,>=1.0 (from graphdatascience->-r requirements.txt (line 2))\n",
      "  Downloading multimethod-1.12-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting neo4j<6.0,>=4.4.12 (from graphdatascience->-r requirements.txt (line 2))\n",
      "  Downloading neo4j-5.28.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting pyarrow>=4.0 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting textdistance<5.0,>=4.0 (from graphdatascience->-r requirements.txt (line 2))\n",
      "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "INFO: pip is looking at multiple versions of graphdatascience to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting graphdatascience (from -r requirements.txt (line 2))\n",
      "  Downloading graphdatascience-1.12-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting pyarrow>=4.0 (from streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.35 (from langchain>=0.0.216->-r requirements.txt (line 4))\n",
      "  Downloading langchain_core-0.3.36-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain>=0.0.216->-r requirements.txt (line 4))\n",
      "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain>=0.0.216->-r requirements.txt (line 4))\n",
      "  Downloading langsmith-0.3.8-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from langchain>=0.0.216->-r requirements.txt (line 4)) (1.4.54)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from langchain>=0.0.216->-r requirements.txt (line 4)) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from langchain>=0.0.216->-r requirements.txt (line 4)) (3.11.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 9)) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from pandas->-r requirements.txt (line 9)) (2025.1)\n",
      "Collecting entrypoints (from altair<5->-r requirements.txt (line 11))\n",
      "  Downloading entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jinja2 (from altair<5->-r requirements.txt (line 11))\n",
      "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<5->-r requirements.txt (line 11))\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting toolz (from altair<5->-r requirements.txt (line 11))\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.216->-r requirements.txt (line 4)) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.216->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.216->-r requirements.txt (line 4)) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.216->-r requirements.txt (line 4)) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.216->-r requirements.txt (line 4)) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.216->-r requirements.txt (line 4)) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain>=0.0.216->-r requirements.txt (line 4)) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai->-r requirements.txt (line 1)) (3.10)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3->streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: certifi in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (2025.1.31)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7,>=1.4->streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<5->-r requirements.txt (line 11))\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<5->-r requirements.txt (line 11))\n",
      "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<5->-r requirements.txt (line 11))\n",
      "  Downloading rpds_py-0.22.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.35->langchain>=0.0.216->-r requirements.txt (line 4))\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.17->langchain>=0.0.216->-r requirements.txt (line 4))\n",
      "  Downloading orjson-3.10.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (41 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain>=0.0.216->-r requirements.txt (line 4))\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.17->langchain>=0.0.216->-r requirements.txt (line 4))\n",
      "  Downloading zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1))\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1))\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from jinja2->altair<5->-r requirements.txt (line 11)) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from python-dateutil<3,>=2->streamlit==1.23.1->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from requests<3,>=2.4->streamlit==1.23.1->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from requests<3,>=2.4->streamlit==1.23.1->-r requirements.txt (line 5)) (2.3.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich<14,>=10.11.0->streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/brandonkeung/.pyenv/versions/3.11.9/envs/Capstone311/lib/python3.11/site-packages (from rich<14,>=10.11.0->streamlit==1.23.1->-r requirements.txt (line 5)) (2.19.1)\n",
      "Collecting pytz-deprecation-shim (from tzlocal<5,>=1.1->streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.35->langchain>=0.0.216->-r requirements.txt (line 4))\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich<14,>=10.11.0->streamlit==1.23.1->-r requirements.txt (line 5))\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
      "Downloading streamlit-1.23.1-py2.py3-none-any.whl (8.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading streamlit_chat-0.0.2.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading streamlit_chat_media-0.0.4-py3-none-any.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.15.0-py2.py3-none-any.whl (15.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading openai-1.63.2-py3-none-any.whl (472 kB)\n",
      "Downloading graphdatascience-1.12-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading altair-4.2.2-py3-none-any.whl (813 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m813.6/813.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Downloading jiter-0.8.2-cp311-cp311-macosx_11_0_arm64.whl (311 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading langchain_core-0.3.36-py3-none-any.whl (413 kB)\n",
      "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
      "Downloading langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
      "Downloading multimethod-1.12-py3-none-any.whl (10 kB)\n",
      "Downloading neo4j-5.28.1-py3-none-any.whl (312 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading Pillow-9.5.0-cp311-cp311-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Downloading pyarrow-16.1.0-cp311-cp311-macosx_11_0_arm64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Downloading Pympler-1.1-py3-none-any.whl (165 kB)\n",
      "Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\n",
      "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
      "Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading orjson-3.10.15-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (249 kB)\n",
      "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading rpds_py-0.22.3-cp311-cp311-macosx_11_0_arm64.whl (349 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading zstandard-0.23.0-cp311-cp311-macosx_11_0_arm64.whl (633 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m633.7/633.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: zstandard, zipp, validators, toolz, toml, textdistance, tenacity, sniffio, smmap, rpds-py, pytz-deprecation-shim, python-dotenv, pympler, pydantic-core, py, protobuf, pillow, packaging, orjson, numpy, neo4j, multimethod, mdurl, jsonpointer, jiter, jinja2, h11, entrypoints, distro, click, cachetools, blinker, annotated-types, tzlocal, retry, requests-toolbelt, referencing, pydeck, pydantic, pyarrow, plotly, markdown-it-py, jsonpatch, importlib-metadata, httpcore, gitdb, anyio, rich, jsonschema-specifications, httpx, graphdatascience, gitpython, openai, langsmith, jsonschema, langchain-core, altair, streamlit, langchain-text-splitters, streamlit-chat-media, streamlit-chat, langchain\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 19.0.0\n",
      "    Uninstalling pyarrow-19.0.0:\n",
      "      Successfully uninstalled pyarrow-19.0.0\n",
      "Successfully installed altair-4.2.2 annotated-types-0.7.0 anyio-4.8.0 blinker-1.9.0 cachetools-5.5.1 click-8.1.8 distro-1.9.0 entrypoints-0.4 gitdb-4.0.12 gitpython-3.1.44 graphdatascience-1.12 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 importlib-metadata-6.11.0 jinja2-3.1.5 jiter-0.8.2 jsonpatch-1.33 jsonpointer-3.0.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 langchain-0.3.19 langchain-core-0.3.36 langchain-text-splitters-0.3.6 langsmith-0.3.8 markdown-it-py-3.0.0 mdurl-0.1.2 multimethod-1.12 neo4j-5.28.1 numpy-1.26.4 openai-1.63.2 orjson-3.10.15 packaging-23.2 pillow-9.5.0 plotly-5.15.0 protobuf-4.25.6 py-1.11.0 pyarrow-16.1.0 pydantic-2.10.6 pydantic-core-2.27.2 pydeck-0.9.1 pympler-1.1 python-dotenv-1.0.0 pytz-deprecation-shim-0.1.0.post0 referencing-0.36.2 requests-toolbelt-1.0.0 retry-0.9.2 rich-13.9.4 rpds-py-0.22.3 smmap-5.0.2 sniffio-1.3.1 streamlit-1.23.1 streamlit-chat-0.0.2.2 streamlit-chat-media-0.0.4 tenacity-8.5.0 textdistance-4.6.3 toml-0.10.2 toolz-1.0.0 tzlocal-4.3.1 validators-0.34.0 zipp-3.21.0 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from string import Template\n",
    "import json\n",
    "from neo4j import GraphDatabase\n",
    "import glob\n",
    "from timeit import default_timer as timer\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv('Code/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai_deployment = \"chat-gpt35\"\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j configuration & constraints\n",
    "neo4j_url = os.getenv(\"NEO4J_CONNECTION_URL\")\n",
    "neo4j_user = os.getenv(\"NEO4J_USER\")\n",
    "neo4j_password = os.getenv(\"NEO4J_PASSWORD\")\n",
    "gds = GraphDatabase.driver(neo4j_url, auth=(neo4j_user, neo4j_password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to call the OpenAI API\n",
    "def process_gpt(file_prompt, system_msg):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        engine=openai_deployment,\n",
    "        max_tokens=15000,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": file_prompt},\n",
    "        ],\n",
    "    )\n",
    "    nlp_results = completion.choices[0].message.content\n",
    "    sleep(8)\n",
    "    return nlp_results\n",
    "\n",
    "\n",
    "# Function to take folder of files and a prompt template, and return a json-object of all the entities and relationships\n",
    "def extract_entities_relationships(folder, prompt_template):\n",
    "    start = timer()\n",
    "    files = glob.glob(f\"./data/{folder}/*\")\n",
    "    system_msg = \"You are a helpful IT-project and account management expert who extracts information from documents.\"\n",
    "    print(f\"Running pipeline for {len(files)} files in {folder} folder\")\n",
    "    results = []\n",
    "    for i, file in enumerate(files):\n",
    "        print(f\"Extracting entities and relationships for {file}\")\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                text = f.read().rstrip()\n",
    "                prompt = Template(prompt_template).substitute(ctext=text)\n",
    "                result = process_gpt(prompt, system_msg=system_msg)\n",
    "                results.append(json.loads(result))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file}: {e}\")\n",
    "    end = timer()\n",
    "    print(f\"Pipeline completed in {end-start} seconds\")\n",
    "    return results\n",
    "\n",
    "\n",
    "# Function to take a json-object of entitites and relationships and generate cypher query for creating those entities\n",
    "def generate_cypher(json_obj):\n",
    "    e_statements = []\n",
    "    r_statements = []\n",
    "\n",
    "    e_label_map = {}\n",
    "\n",
    "    # loop through our json object\n",
    "    for i, obj in enumerate(json_obj):\n",
    "        print(f\"Generating cypher for file {i+1} of {len(json_obj)}\")\n",
    "        for entity in obj[\"entities\"]:\n",
    "            label = entity[\"label\"]\n",
    "            id = entity[\"id\"]\n",
    "            id = id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            properties = {k: v for k, v in entity.items() if k not in [\"label\", \"id\"]}\n",
    "\n",
    "            cypher = f'MERGE (n:{label} {{id: \"{id}\"}})'\n",
    "            if properties:\n",
    "                props_str = \", \".join(\n",
    "                    [f'n.{key} = \"{val}\"' for key, val in properties.items()]\n",
    "                )\n",
    "                cypher += f\" ON CREATE SET {props_str}\"\n",
    "            e_statements.append(cypher)\n",
    "            e_label_map[id] = label\n",
    "\n",
    "        for rs in obj[\"relationships\"]:\n",
    "            src_id, rs_type, tgt_id = rs.split(\"|\")\n",
    "            src_id = src_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "            tgt_id = tgt_id.replace(\"-\", \"\").replace(\"_\", \"\")\n",
    "\n",
    "            src_label = e_label_map[src_id]\n",
    "            tgt_label = e_label_map[tgt_id]\n",
    "\n",
    "            cypher = f'MERGE (a:{src_label} {{id: \"{src_id}\"}}) MERGE (b:{tgt_label} {{id: \"{tgt_id}\"}}) MERGE (a)-[:{rs_type}]->(b)'\n",
    "            r_statements.append(cypher)\n",
    "\n",
    "    with open(\"cyphers.txt\", \"w\") as outfile:\n",
    "        outfile.write(\"\\n\".join(e_statements + r_statements))\n",
    "\n",
    "    return e_statements + r_statements\n",
    "\n",
    "\n",
    "# Final function to bring all the steps together\n",
    "def ingestion_pipeline(folders):\n",
    "    # Extrating the entites and relationships from each folder, append into one json_object\n",
    "    entities_relationships = []\n",
    "    for key, value in folders.items():\n",
    "        entities_relationships.extend(extract_entities_relationships(key, value))\n",
    "\n",
    "    # Generate and execute cypher statements\n",
    "    cypher_statements = generate_cypher(entities_relationships)\n",
    "    for i, stmt in enumerate(cypher_statements):\n",
    "        print(f\"Executing cypher statement {i+1} of {len(cypher_statements)}\")\n",
    "        try:\n",
    "            gds.execute_query(stmt)\n",
    "        except Exception as e:\n",
    "            with open(\"failed_statements.txt\", \"w\") as f:\n",
    "                f.write(f\"{stmt} - Exception: {e}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_products_prompt_template = \"\"\"\n",
    "From the list of products below, extract the following Entities & Relationships in the specified format:\n",
    "0. ALWAYS FINISH THE OUTPUT. Never send partial responses.\n",
    "1. First, identify these Entity types in the text and generate them as comma-separated values similar to the entity type format.\n",
    "    The `id` property of each entity must be alphanumeric and unique among all entities. Use this property to define relationships between entities. Do not create new entity types beyond those listed below. Generate as many entities as needed based on the types provided:\n",
    "    \n",
    "    Entity Types:\n",
    "   label:'Product',id:string,title:string,description:string,price:float,averageRating:float //Represents a product. 'id' should be a unique alphanumeric identifier (e.g., 'anomieBonhomie'), 'title' is the product's name, 'description' is the full product description, 'price' is the product's price (use 0.0 for 'nan' values), and 'averageRating' is the average customer rating.\n",
    "    \n",
    "   label:'Category',id:string,name:string //Represents the product category. 'id' should be a camel-case version of the category name (e.g., 'digitalMusic'), and 'name' is the full category name.\n",
    "    \n",
    "   label:'Store',id:string,name:string //Represents the store or brand offering the product. 'id' should be a camel-case version of the store name (e.g., 'scrittiPolitti'), and 'name' is the full store name.\n",
    "    \n",
    "   label:'Format',id:string,name:string //Represents the product format (e.g., 'Audio CD'). 'id' should be a camel-case version of the format name (e.g., 'audioCD'), and 'name' is the format's full name.\n",
    "    \n",
    "2. Next, generate each relationship as triples of head, relationship, and tail. Use the respective `id` properties to refer to the head and tail entities. Relationship properties should be mentioned within brackets as comma-separated values. Generate as many relationships as needed, using the following relationship types:\n",
    "\n",
    "    Relationship Types:\n",
    "    productid|BELONGS_TO|categoryid\n",
    "    productid|SOLD_BY|storeid\n",
    "    productid|HAS_FORMAT|formatid\n",
    "\n",
    "3. The output should be formatted as:\n",
    "{\n",
    "    \"entities\": [\n",
    "        {\"label\":\"Product\",\"id\":string,\"title\":string,\"description\":string,\"price\":float,\"averageRating\":float},\n",
    "        {\"label\":\"Category\",\"id\":string,\"name\":string},\n",
    "        {\"label\":\"Store\",\"id\":string,\"name\":string},\n",
    "        {\"label\":\"Format\",\"id\":string,\"name\":string}\n",
    "    ],\n",
    "    \"relationships\": [\n",
    "        \"productid|BELONGS_TO|categoryid\",\n",
    "        \"productid|SOLD_BY|storeid\",\n",
    "        \"productid|HAS_FORMAT|formatid\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "Case Sheet:\n",
    "$ctext\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = {\n",
    "    \"amazon_products\": amazon_products_prompt_template,\n",
    "}\n",
    "ingestion_pipeline(folders)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capstone311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
