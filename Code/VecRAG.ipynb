{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector RAG Pipeline\n",
    "1. QA pipeline with LangChain\n",
    "2. Persistent vector storage based on ChromaDB\n",
    "3. Evaluation with ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import huggingface_hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('private-config.env'):\n",
    "    load_dotenv('private-config.env', override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hf_token = os.getenv('HF_TOKEN')\n",
    "# # Use the token with the Hugging Face library\n",
    "# huggingface_hub.login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "# model_kwargs = {\"device\": \"cpu\"}\n",
    "# encode_kwargs = {\"normalize_embeddings\": False}\n",
    "# embeddings = HuggingFaceEmbeddings(\n",
    "#     model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 13, 'total_tokens': 43, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b376dfbbd5', 'id': 'chatcmpl-BKcVyJc26L3xvcgaVJBd77zD5ms7C', 'finish_reason': 'stop', 'logprobs': None}, id='run-933492c3-a745-4bde-b19c-7195b50e6122-0', usage_metadata={'input_tokens': 13, 'output_tokens': 30, 'total_tokens': 43, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test LLM\n",
    "response = llm.invoke(\"Hello, how are you?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
    "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
    "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
    "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\",\n",
    "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(page_content=doc) for doc in sample_docs]\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "docstore = text_splitter.split_documents(documents)\n",
    "\n",
    "# Create ChromaDB and store embeddings\n",
    "db = Chroma.from_documents(docstore, embeddings, persist_directory=\"./chroma_db\")\n",
    "\n",
    "# Create a retriever\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.vectorstores.base.VectorStoreRetriever"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Context:\n",
      " 'On the Origin of Species'.\n",
      "\n",
      "the foundation for classical mechanics.\n",
      "\n",
      "of time, space, and gravity.\n",
      "\n",
      "and won two Nobel Prizes.\n",
      "\n",
      "Albert Einstein proposed the theory of relativity, which transformed our understanding of time,\n"
     ]
    }
   ],
   "source": [
    "# Querying ChromaDB to Get Context\n",
    "query = \"What is the key takeaway from the document?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "retrieved_context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "print(\"Retrieved Context:\\n\", retrieved_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Response:\n",
      " The key takeaway from the document is that significant scientific advancements, such as Darwin's theory of evolution in \"On the Origin of Species\" and Einstein's theory of relativity, have fundamentally transformed our understanding of natural phenomena, including the principles of classical mechanics and the concepts of time, space, and gravity.\n"
     ]
    }
   ],
   "source": [
    "# Define an LLM and Generate Response Using Context\n",
    "prompt = f\"\"\"\n",
    "Based on the following context, answer the question:\\n\n",
    "Context: \\n\n",
    "{retrieved_context}\\n\n",
    "Question: {query}\\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "response = llm.invoke(prompt)\n",
    "print(\"\\nGenerated Response:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_queries = [\n",
    "    \"Who introduced the theory of relativity?\",\n",
    "    \"Who was the first computer programmer?\",\n",
    "    \"What did Isaac Newton contribute to science?\",\n",
    "    \"Who won two Nobel Prizes for research on radioactivity?\",\n",
    "    \"What is the theory of evolution by natural selection?\"\n",
    "]\n",
    "\n",
    "expected_responses = [\n",
    "    \"Albert Einstein proposed the theory of relativity, which transformed our understanding of time, space, and gravity.\",\n",
    "    \"Ada Lovelace is regarded as the first computer programmer for her work on Charles Babbage's early mechanical computer, the Analytical Engine.\",\n",
    "    \"Isaac Newton formulated the laws of motion and universal gravitation, laying the foundation for classical mechanics.\",\n",
    "    \"Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity and won two Nobel Prizes.\",\n",
    "    \"Charles Darwin introduced the theory of evolution by natural selection in his book 'On the Origin of Species'.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:09,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dataset = []\n",
    "\n",
    "for query,reference in tqdm(zip(sample_queries,expected_responses)):\n",
    "\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "    relevant_context = \"\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    prompt = f\"Based on the following context, answer the question:\\n\\n{relevant_context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    response = llm.invoke(prompt).content\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":query,\n",
    "            \"retrieved_contexts\":[d.page_content for d in relevant_docs],\n",
    "            \"response\":response,\n",
    "            \"reference\":reference\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0624ded833c044459a22626add4b41f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 1.0000, 'faithfulness': 0.9000, 'factual_correctness(mode=f1)': 0.7140, 'answer_correctness': 0.6546, 'answer_relevancy': 0.9517, 'context_precision': 0.9000}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, AnswerCorrectness, AnswerRelevancy, ContextRecall, ContextPrecision\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(llm)\n",
    "\n",
    "metrics_list = [\n",
    "    LLMContextRecall(),\n",
    "    Faithfulness(),\n",
    "    FactualCorrectness(),\n",
    "    AnswerCorrectness(),\n",
    "    AnswerRelevancy(),\n",
    "    ContextRecall(),\n",
    "    ContextPrecision()\n",
    "]\n",
    "result = evaluate(dataset=evaluation_dataset,metrics=metrics_list,llm=evaluator_llm)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
